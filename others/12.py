import os
import time
import cv2
import numpy as np
from sklearn.cluster import KMeans
from scipy.cluster.vq import vq
import tkinter as tk
from tkinter import filedialog, messagebox
from tkinter import ttk
from PIL import Image, ImageTk
import joblib
from collections import defaultdict
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, average_precision_score

from math import log


class ImageRetrievalApp:
    def __init__(self, root):
        """åˆå§‹åŒ–å›¾åƒæ£€ç´¢åº”ç”¨ç¨‹åº"""
        self.root = root
        self.root.title("å›¾åƒæ£€ç´¢ç³»ç»Ÿ (TF-IDFå€’æ’ç´¢å¼•ç‰ˆ)")
        self.root.geometry("1200x800")

        # åˆå§‹åŒ–ç³»ç»Ÿå˜é‡
        self.train_folder = None  # è®­ç»ƒé›†è·¯å¾„
        self.test_folder = None  # æµ‹è¯•é›†è·¯å¾„
        self.dictionary = None  # è§†è§‰è¯å…¸ï¼ˆèšç±»ä¸­å¿ƒï¼‰
        self.idf = None  # IDFæƒé‡å‘é‡ï¼ˆnumpyæ•°ç»„ï¼‰
        self.train_features = []  # è®­ç»ƒé›†ç‰¹å¾å‘é‡ï¼ˆTF-IDFï¼‰
        self.test_features = []  # æµ‹è¯•é›†ç‰¹å¾å‘é‡
        self.train_images_paths = []  # è®­ç»ƒå›¾åƒè·¯å¾„åˆ—è¡¨
        self.test_images_paths = []  # æµ‹è¯•å›¾åƒè·¯å¾„åˆ—è¡¨
        self.train_labels = []  # è®­ç»ƒå›¾åƒç±»åˆ«æ ‡ç­¾
        self.ap_history = []  # ä¿å­˜æ¯æ¬¡æ£€ç´¢çš„APå€¼
        self.recall_history = []  # ä¿å­˜æ¯æ¬¡æ£€ç´¢çš„å¬å›ç‡
        self.inverted_index = defaultdict(list)  # å€’æ’ç´¢å¼•ç»“æ„ï¼š{word: [(img_idx, weight)]}

        # è‡ªåŠ¨åŠ è½½å·²æœ‰æ¨¡å‹å’Œæ•°æ®
        self.load_saved_models()

        # åˆå§‹åŒ–ç•Œé¢
        self.create_widgets()

    def create_widgets(self):
        """åˆ›å»ºGUIç•Œé¢ç»„ä»¶"""
        # ä¸»å®¹å™¨
        main_frame = tk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True)

        # æŒ‡æ ‡æ˜¾ç¤ºé¢æ¿
        metrics_frame = tk.Frame(main_frame, relief=tk.RAISED, bd=1)
        metrics_frame.pack(fill=tk.X, pady=5, padx=5)

        # å®šä¹‰æŒ‡æ ‡æ˜¾ç¤ºæ ·å¼
        metric_config = {'font': ('å®‹ä½“', 10), 'width': 15}
        self.ap_label = tk.Label(metrics_frame, text="AP: 0.0000", **metric_config)
        self.ap_label.pack(side=tk.LEFT, padx=10)

        self.recall_label = tk.Label(metrics_frame, text="å¬å›ç‡: 0.0000", **metric_config)
        self.recall_label.pack(side=tk.LEFT, padx=10)

        self.map_label = tk.Label(metrics_frame, text="MAP: 0.0000", **metric_config)
        self.map_label.pack(side=tk.LEFT, padx=10)

        self.mar_label = tk.Label(metrics_frame, text="MAR: 0.0000", **metric_config)
        self.mar_label.pack(side=tk.LEFT, padx=10)

        # æ§åˆ¶æŒ‰é’®é¢æ¿
        button_frame = tk.Frame(main_frame)
        button_frame.pack(pady=10, fill=tk.X)

        # åŠŸèƒ½æŒ‰é’®é…ç½®
        buttons = [
            ("é€‰æ‹©è®­ç»ƒé›†", self.select_train_folder),
            ("é€‰æ‹©æµ‹è¯•é›†", self.select_test_folder),
            ("ç”Ÿæˆè§†è§‰è¯å…¸", self.generate_dictionary),
            ("ç¼–ç è®­ç»ƒé›†", self.encode_train_images),
            ("ç¼–ç æµ‹è¯•é›†", self.encode_test_images),
            ("å›¾åƒæ£€ç´¢", self.select_image_and_search),
            ("ç»˜åˆ¶PRæ›²çº¿", self.evaluate_all_queries_and_plot_pr)
        ]

        # æ’åˆ—æŒ‰é’®
        for idx, (text, cmd) in enumerate(buttons):
            btn = tk.Button(button_frame, text=text, command=cmd, width=12)
            btn.grid(row=0, column=idx, padx=5)

        # æŸ¥è¯¢å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        self.query_frame = tk.Frame(main_frame, height=180)
        self.query_frame.pack(fill=tk.X, pady=5)

        # æ£€ç´¢ç»“æœå±•ç¤ºåŒºåŸŸ
        result_container = tk.Frame(main_frame)
        result_container.pack(fill=tk.BOTH, expand=True)

        # æ»šåŠ¨æ¡å’Œç”»å¸ƒé…ç½®
        self.canvas = tk.Canvas(result_container)
        self.scrollbar = ttk.Scrollbar(result_container, orient="vertical", command=self.canvas.yview)
        self.canvas.configure(yscrollcommand=self.scrollbar.set)

        # ç»“æœå±•ç¤ºå†…éƒ¨æ¡†æ¶
        self.result_frame = tk.Frame(self.canvas)
        self.canvas.create_window((0, 0), window=self.result_frame, anchor="nw")

        # å¸ƒå±€ç»„ä»¶
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)

        # çŠ¶æ€æ 
        self.status_bar = tk.Label(main_frame, text="å°±ç»ª", bd=1, relief=tk.SUNKEN, anchor=tk.W)
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

        # ç»‘å®šç”»å¸ƒæ»šåŠ¨äº‹ä»¶
        self.result_frame.bind("<Configure>", lambda e: self.canvas.configure(
            scrollregion=self.canvas.bbox("all")))

    # æ ¸å¿ƒåŠŸèƒ½æ–¹æ³• ------------------------------------------------------------

    def evaluate_all_queries_and_plot_pr(self):
        """å¯¹æµ‹è¯•é›†æ‰€æœ‰å›¾åƒæ‰§è¡Œæ£€ç´¢å¹¶è¾“å‡ºPRæ›²çº¿ã€P@Kã€R@Kã€MAPç­‰æŒ‡æ ‡"""
        if not self.test_features or not self.test_images_paths:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç¼–ç æµ‹è¯•é›†ï¼")
            return

        all_labels = []
        all_scores = []

        # ç»Ÿè®¡æŒ‡æ ‡
        ap_list = []
        recall_list = []
        precision_at_k = {1: [], 5: [], 10: []}
        recall_at_k = {1: [], 5: [], 10: []}

        for test_vector, test_path in zip(self.test_features, self.test_images_paths):
            query_class = os.path.basename(os.path.dirname(test_path))
            total_relevant = sum(1 for label in self.train_labels if label == query_class)

            scores = defaultdict(float)
            query_words = np.where(test_vector > 1e-6)[0]

            for word in query_words:
                for img_idx, weight in self.inverted_index.get(word, []):
                    scores[img_idx] += weight * test_vector[word]

            sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
            retrieved_indices = [i for i, _ in sorted_scores]
            retrieved_scores = [s for _, s in sorted_scores]

            relevance = [1 if self.train_labels[i] == query_class else 0 for i in retrieved_indices]
            all_labels.extend(relevance)
            all_scores.extend(retrieved_scores)

            # è®¡ç®—APå’ŒRecall
            relevance_array = np.array(relevance)
            cumsum = np.cumsum(relevance_array)
            precision = cumsum / (np.arange(len(relevance_array)) + 1)
            if total_relevant > 0:
                ap = np.sum(precision * relevance_array) / total_relevant
                recall = np.sum(relevance_array) / total_relevant
            else:
                ap = 0
                recall = 0
            ap_list.append(ap)
            recall_list.append(recall)

            for k in [1, 5, 10]:
                top_k = relevance[:k]
                retrieved_k = min(len(top_k), total_relevant) if total_relevant > 0 else 1
                precision_at_k[k].append(sum(top_k) / k)
                recall_at_k[k].append(sum(top_k) / retrieved_k)

        # è®¡ç®—æ•´ä½“PRæ›²çº¿
        precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_scores)
        ap_total = average_precision_score(all_labels, all_scores)

        # ç»˜å›¾
        plt.figure(figsize=(6, 5))
        plt.plot(recall_curve, precision_curve, label=f'AP = {ap_total:.4f}', color='blue')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.savefig("pr_curve.png")
        plt.show()

        # æ§åˆ¶å°è¾“å‡ºç»“æœ
        print("=" * 50)
        print("ğŸ“Š æ£€ç´¢æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼š")
        print(f"MAP (Mean Average Precision): {np.mean(ap_list):.4f}")
        print(f"MAR (Mean Average Recall):    {np.mean(recall_list):.4f}")
        for k in [1, 5, 10]:
            print(f"Precision@{k}: {np.mean(precision_at_k[k]):.4f}")
            print(f"Recall@{k}:    {np.mean(recall_at_k[k]):.4f}")
        print("=" * 50)

        self.status_bar.config(
            text=f"PRæ›²çº¿å®Œæˆ | MAP: {np.mean(ap_list):.4f} | P@10: {np.mean(precision_at_k[10]):.4f}")

    def load_saved_models(self):
        """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹å’Œæ•°æ®"""
        try:
            # åŠ è½½è§†è§‰è¯å…¸
            if os.path.exists('../visual_dictionary.pkl'):
                self.dictionary = joblib.load('../visual_dictionary.pkl')

            # åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆåŒ…å«å€’æ’ç´¢å¼•å’ŒIDFï¼‰
            if os.path.exists('../train_data.pkl'):
                data = joblib.load('../train_data.pkl')
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if len(data) != 5:
                    raise ValueError("è®­ç»ƒæ•°æ®æ ¼å¼ä¸å…¼å®¹")

                # è§£åŒ…æ•°æ®ï¼šç¡®ä¿é¡ºåºæ­£ç¡®
                (self.train_features,
                 self.train_images_paths,
                 self.train_labels,
                 self.inverted_index,
                 self.idf) = data

                # å¼ºåˆ¶ç±»å‹è½¬æ¢ç¡®ä¿è®¡ç®—å®‰å…¨
                self.idf = self.idf.astype(np.float64)
                self.train_features = [v.astype(np.float64) for v in self.train_features]

        except Exception as e:
            messagebox.showerror("åŠ è½½é”™è¯¯", f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
            # åˆ é™¤æŸåæ–‡ä»¶
            if os.path.exists('../train_data.pkl'):
                os.remove('../train_data.pkl')
            self.dictionary = None
            self.idf = None

    def select_train_folder(self):
        """é€‰æ‹©è®­ç»ƒé›†ç›®å½•"""
        self.train_folder = filedialog.askdirectory()
        self.status_bar.config(text=f"è®­ç»ƒé›†è·¯å¾„: {self.train_folder}")

    def select_test_folder(self):
        """é€‰æ‹©æµ‹è¯•é›†ç›®å½•"""
        self.test_folder = filedialog.askdirectory()
        self.status_bar.config(text=f"æµ‹è¯•é›†è·¯å¾„: {self.test_folder}")

    def generate_dictionary(self):
        """ç”Ÿæˆè§†è§‰è¯å…¸ï¼ˆè§†è§‰å•è¯èšç±»ä¸­å¿ƒï¼‰"""
        # æ£€æŸ¥å·²æœ‰è¯å…¸
        if os.path.exists('../visual_dictionary.pkl'):
            self.dictionary = joblib.load('../visual_dictionary.pkl')
            messagebox.showinfo("æç¤º", "å·²åŠ è½½ç°æœ‰è§†è§‰è¯å…¸ï¼")
            return

        # åˆå§‹åŒ–SIFTç‰¹å¾æ£€æµ‹å™¨
        sift = cv2.SIFT_create()
        descriptors_list = []

        # éå†è®­ç»ƒé›†æå–ç‰¹å¾
        for folder, _, filenames in os.walk(self.train_folder):
            for filename in filenames:
                if filename.lower().endswith(('jpg', 'jpeg', 'png')):
                    img_path = os.path.join(folder, filename)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    # æå–SIFTç‰¹å¾
                    keypoints, descriptors = sift.detectAndCompute(img, None)
                    if descriptors is not None:
                        descriptors_list.append(descriptors)

        # æ£€æŸ¥ç‰¹å¾æœ‰æ•ˆæ€§
        if not descriptors_list:
            messagebox.showerror("é”™è¯¯", "æœªæå–åˆ°ä»»ä½•ç‰¹å¾ï¼")
            return

        # åˆå¹¶æ‰€æœ‰æè¿°ç¬¦å¹¶è¿›è¡ŒK-meansèšç±»
        descriptors_stack = np.vstack(descriptors_list)
        kmeans = KMeans(n_clusters=1000, random_state=42, n_init=10)
        kmeans.fit(descriptors_stack)

        # ä¿å­˜è§†è§‰è¯å…¸
        self.dictionary = kmeans.cluster_centers_
        joblib.dump(self.dictionary, '../visual_dictionary.pkl')
        messagebox.showinfo("æç¤º", f"è§†è§‰è¯å…¸å·²ç”Ÿæˆï¼å…±{len(self.dictionary)}ä¸ªè§†è§‰å•è¯")

    def encode_train_images(self):
        """ç¼–ç è®­ç»ƒé›†å›¾åƒå¹¶æ„å»ºå€’æ’ç´¢å¼•"""
        # å‰ç½®æ£€æŸ¥
        if self.dictionary is None:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç”Ÿæˆè§†è§‰è¯å…¸ï¼")
            return
        if os.path.exists('../train_data.pkl'):
            messagebox.showinfo("æç¤º", "å·²åŠ è½½è®­ç»ƒæ•°æ®ï¼")
            return

        sift = cv2.SIFT_create()
        df = np.zeros(self.dictionary.shape[0], dtype=np.int32)  # æ–‡æ¡£é¢‘ç‡ç»Ÿè®¡
        tf_features = []  # ä¸´æ—¶å­˜å‚¨TFç‰¹å¾
        self.train_images_paths = []
        self.train_labels = []

        # ç¬¬ä¸€è½®éå†ï¼šè®¡ç®—æ–‡æ¡£é¢‘ç‡ï¼ˆDFï¼‰
        for root_dir, _, filenames in os.walk(self.train_folder):
            class_name = os.path.basename(root_dir)
            for filename in filenames:
                if filename.lower().endswith(('jpg', 'jpeg', 'png')):
                    img_path = os.path.join(root_dir, filename)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    # æå–ç‰¹å¾å¹¶é‡åŒ–åˆ°è§†è§‰è¯å…¸
                    keypoints, descriptors = sift.detectAndCompute(img, None)
                    if descriptors is not None:
                        words, _ = vq(descriptors, self.dictionary)
                        # ç»Ÿè®¡æ¯ä¸ªè§†è§‰å•è¯å‡ºç°çš„æ–‡æ¡£æ•°
                        present_words = np.unique(words)
                        df[present_words] += 1
                        # è®°å½•è¯é¢‘ï¼ˆTFï¼‰
                        hist, _ = np.histogram(words, bins=np.arange(len(self.dictionary) + 1))
                        tf_features.append(hist)
                        self.train_images_paths.append(img_path)
                        self.train_labels.append(class_name)

        # è®¡ç®—IDFï¼ˆé€†æ–‡æ¡£é¢‘ç‡ï¼‰
        N = len(tf_features)  # æ€»æ–‡æ¡£æ•°
        self.idf = np.log(N / (df.astype(float) + 1e-6))  # æ·»åŠ å¹³æ»‘é¡¹é¿å…é™¤é›¶

        # è½¬æ¢ä¸ºTF-IDFå¹¶å½’ä¸€åŒ–
        self.train_features = []
        for tf in tf_features:
            tf = tf.astype(float)
            tf_idf = tf * self.idf  # è®¡ç®—TF-IDF
            norm = np.linalg.norm(tf_idf)
            tf_idf_normalized = tf_idf / (norm + 1e-10)  # L2å½’ä¸€åŒ–
            self.train_features.append(tf_idf_normalized)

        # æ„å»ºå€’æ’ç´¢å¼•
        self.build_inverted_index()

        # ä¿å­˜è®­ç»ƒæ•°æ®
        joblib.dump(
            (self.train_features,
             self.train_images_paths,
             self.train_labels,
             self.inverted_index,
             self.idf.astype(np.float32)),  # å‹ç¼©å­˜å‚¨
            '../train_data.pkl'
        )
        self.status_bar.config(text=f"è®­ç»ƒé›†ç¼–ç å®Œæˆï¼å…±ç¼–ç {len(self.train_features)}å¼ å›¾åƒ")

    def build_inverted_index(self):
        """æ„å»ºå€’æ’ç´¢å¼•ç»“æ„"""
        self.inverted_index = defaultdict(list)
        for img_idx, feature in enumerate(self.train_features):
            # æå–éé›¶æƒé‡ç‰¹å¾
            non_zero = np.where(feature > 1e-6)[0]
            for word in non_zero:
                # å­˜å‚¨æ ¼å¼ï¼š(å›¾åƒç´¢å¼•, æƒé‡)
                self.inverted_index[word].append((img_idx, feature[word]))

    def encode_test_images(self):
        """ç¼–ç æµ‹è¯•é›†å›¾åƒ"""
        # å‰ç½®æ£€æŸ¥
        if self.dictionary is None or self.idf is None:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç¼–ç è®­ç»ƒé›†ï¼")
            return

        sift = cv2.SIFT_create()
        self.test_features = []
        self.test_images_paths = []

        # éå†æµ‹è¯•é›†
        for root_dir, _, filenames in os.walk(self.test_folder):
            for filename in filenames:
                if filename.lower().endswith(('jpg', 'jpeg', 'png')):
                    img_path = os.path.join(root_dir, filename)
                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    # æå–ç‰¹å¾å¹¶é‡åŒ–
                    keypoints, descriptors = sift.detectAndCompute(img, None)
                    if descriptors is not None:
                        words, _ = vq(descriptors, self.dictionary)
                        # è®¡ç®—TF-IDF
                        hist, _ = np.histogram(words, bins=np.arange(len(self.dictionary) + 1))
                        tf_idf = hist.astype(float) * self.idf
                        norm = np.linalg.norm(tf_idf)
                        tf_idf_normalized = tf_idf / (norm + 1e-10)
                        self.test_features.append(tf_idf_normalized)
                        self.test_images_paths.append(img_path)

        joblib.dump((self.test_features, self.test_images_paths), '../test_data.pkl')
        self.status_bar.config(text=f"æµ‹è¯•é›†ç¼–ç å®Œæˆï¼å…±ç¼–ç {len(self.test_features)}å¼ å›¾åƒ")

    def select_image_and_search(self):
        """é€‰æ‹©æŸ¥è¯¢å›¾åƒå¹¶æ‰§è¡Œæ£€ç´¢"""
        file_path = filedialog.askopenfilename(
            filetypes=[("å›¾ç‰‡æ–‡ä»¶", "*.jpg;*.jpeg;*.png")])
        if file_path:
            self.search_image(file_path)

    def search_image(self, image_path):
        """æ‰§è¡Œå›¾åƒæ£€ç´¢"""
        # å‰ç½®æ£€æŸ¥
        if not self.train_features:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆç¼–ç è®­ç»ƒé›†ï¼")
            return

        start_time = time.time()

        # æå–æŸ¥è¯¢å›¾åƒç‰¹å¾
        sift = cv2.SIFT_create()
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        keypoints, descriptors = sift.detectAndCompute(img, None)

        if descriptors is None:
            messagebox.showerror("é”™è¯¯", "æ— æ³•æå–å›¾åƒç‰¹å¾ï¼")
            return

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        words, _ = vq(descriptors, self.dictionary)
        hist, _ = np.histogram(words, bins=np.arange(len(self.dictionary) + 1))
        tf_idf_query = hist.astype(float) * self.idf
        norm = np.linalg.norm(tf_idf_query)
        query_vector = tf_idf_query / (norm + 1e-10)

        # å€’æ’ç´¢å¼•æ£€ç´¢ --------------------------------------------------------
        scores = defaultdict(float)  # å­˜å‚¨å›¾åƒå¾—åˆ†
        query_words = np.where(query_vector > 1e-6)[0]  # æŸ¥è¯¢åŒ…å«çš„è§†è§‰å•è¯


        for word in query_words:
            # è·å–å€’æ’åˆ—è¡¨ä¸­çš„(å›¾åƒç´¢å¼•, æƒé‡)å¯¹
            for img_idx, weight in self.inverted_index.get(word, []):
                # ç´¯åŠ ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦åˆ†è§£è®¡ç®—ï¼‰
                scores[img_idx] += weight * query_vector[word]
        search_time = time.time() - start_time

        # è·å–Top10ç»“æœ
        top_k = 10
        sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
        top_candidates = [item[0] for item in sorted_scores]
        distances = [1 - item[1] for item in sorted_scores]  # è½¬æ¢ä¸ºè·ç¦»å€¼

        # è¯„ä¼°æŒ‡æ ‡è®¡ç®— --------------------------------------------------------
        query_class = os.path.basename(os.path.dirname(image_path))
        total_relevant = sum(1 for label in self.train_labels if label == query_class)
        ap = 0.0
        recall = 0.0

        if total_relevant > 0:
            # è®¡ç®—æ£€ç´¢ç»“æœçš„äºŒå€¼ç›¸å…³æ€§
            retrieved_labels = [self.train_labels[i] for i in top_candidates]
            binary_relevance = np.array([1 if label == query_class else 0 for label in retrieved_labels])

            # è®¡ç®—å¬å›ç‡
            relevant_retrieved = np.sum(binary_relevance)
            recall = relevant_retrieved / total_relevant

            # è®¡ç®—å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰
            cumsum = np.cumsum(binary_relevance)
            precision_at_k = cumsum / (np.arange(len(binary_relevance)) + 1)
            ap = np.sum(precision_at_k * binary_relevance) / top_k

            # è®°å½•å†å²æŒ‡æ ‡
            self.ap_history.append(ap)
            self.recall_history.append(recall)
        else:
            messagebox.showwarning("è­¦å‘Š", "æœªæ‰¾åˆ°ç›¸å…³ç±»åˆ«å›¾åƒï¼")

        # æ›´æ–°å…¨å±€æŒ‡æ ‡
        map_value = np.mean(self.ap_history) if self.ap_history else 0.0
        mar_value = np.mean(self.recall_history) if self.recall_history else 0.0

        self.ap_label.config(text=f"AP: {ap:.4f}")
        self.recall_label.config(text=f"å¬å›ç‡: {recall:.4f}")
        self.map_label.config(text=f"MAP: {map_value:.4f}")
        self.mar_label.config(text=f"MAR: {mar_value:.4f}")

        # æ˜¾ç¤ºç»“æœ
        self.show_query_image(image_path)
        self.show_results(top_candidates, distances, search_time)

    def show_query_image(self, image_path):
        """æ˜¾ç¤ºæŸ¥è¯¢å›¾åƒ"""
        # æ¸…ç©ºæ—§å†…å®¹
        for widget in self.query_frame.winfo_children():
            widget.destroy()

        # åŠ è½½å¹¶æ˜¾ç¤ºå›¾åƒ
        img = Image.open(image_path)
        img = img.resize((160, 160), Image.LANCZOS)
        img_tk = ImageTk.PhotoImage(img)

        label = tk.Label(self.query_frame, image=img_tk)
        label.image = img_tk
        label.pack(side=tk.LEFT, padx=10, pady=5)
        tk.Label(self.query_frame, text="æŸ¥è¯¢å›¾ç‰‡", font=('å®‹ä½“', 10)).pack(side=tk.LEFT)

    def show_results(self, indices, distances, search_time):
        """æ˜¾ç¤ºæ£€ç´¢ç»“æœ"""
        # æ¸…ç©ºæ—§ç»“æœ
        for widget in self.result_frame.winfo_children():
            widget.destroy()

        # æ˜¾ç¤ºæ¯ä¸ªç»“æœå›¾åƒ
        for idx, (img_idx, distance) in enumerate(zip(indices, distances)):
            img_path = self.train_images_paths[img_idx]
            try:
                img = Image.open(img_path)
                img = img.resize((150, 150), Image.LANCZOS)
                img_tk = ImageTk.PhotoImage(img)

                # åˆ›å»ºç»“æœæ¡ç›®å®¹å™¨
                frame = tk.Frame(self.result_frame)
                frame.grid(row=idx // 5, column=idx % 5, padx=10, pady=10)

                # æ˜¾ç¤ºå›¾åƒå’Œç›¸ä¼¼åº¦
                label = tk.Label(frame, image=img_tk)
                label.image = img_tk
                label.pack()
                tk.Label(frame, text=f"ç›¸ä¼¼åº¦: {1 - distance:.4f}", font=('å®‹ä½“', 8)).pack()
            except Exception as e:
                print(f"åŠ è½½å›¾ç‰‡å¤±è´¥: {img_path} - {str(e)}")

        # æ›´æ–°çŠ¶æ€æ 
        self.status_bar.config(text=f"æ£€ç´¢å®Œæˆï¼è€—æ—¶: {search_time:.4f}s | è¿”å›ç»“æœ: {len(indices)} å¼ ")


if __name__ == '__main__':
    root = tk.Tk()
    app = ImageRetrievalApp(root)
    root.mainloop()